# 1.为什么会采用三次握手，若采用二次握手可以吗？

[答案](https://www.zhihu.com/question/24853633/answer/573627478)

[详解](https://segmentfault.com/a/1190000039165592)

> `TCP` 需要 `seq` （序列号）来做**可靠重传或接收**，为了避免**连接复用**时无法分辨出 `seq`是**延迟或者是旧链接**的 `seq`，需要三次握手来约定确定双方的`ISN`（初始 `seq` 序列号）。

![img](https://github.com/NoAlligator/pico/blob/main/img/1460000039165594?raw=true)

# 2.为什么会采用四次挥手？

[详解](https://segmentfault.com/a/1190000039165592)

由于 `TCP`的**半关闭**（`half-close`）特性，`TCP` 提供了**连接的一端在结束它的发送后还能接收来自另一端数据的能力。**任何一方**都可以在数据传送结束后发出连接释放的通知**，待对方确认后进入**半关闭状态**。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就**完全关闭**了`TCP`连接。

（1）第一次挥手

因此当主动方发送断开连接的请求（即`FIN`报文）给被动方时，**仅仅代表主动方不会再发送数据报文了，但主动方仍可以接收数据报文。**

​    （2）第二次挥手

被动方此时有可能还有相应的数据报文需要发送，因此需要先发送`ACK`报文，告知主动方“我知道你想断开连接的请求了”。**这样主动方便不会因为没有收到应答而继续发送断开连接的请求**（即`FIN`报文）。

   （3）第三次挥手

被动方在处理完数据报文后，便发送给主动方FIN报文；这样可以**保证数据通信正常可靠地完成**。发送完FIN报文后，被动方进入`LAST_ACK`阶段（超时等待）。

   （4）第四挥手

如果主动方及时发送`ACK`报文进行连接中断的确认，这时被动方就直接释放连接，进入可用状态。这一步是确保被动方获知自己发送的`FIN`报文已经被主动方接收到，防止被动方再次发送`FIN`报文。

# 3.说一说代理、网关和隧道？

## 代理

代理是一种**有转发功能**的应用程序，它扮演了位于**服务器和客户端“中间人”**的角色，**接收由客户端发送的请求并转发给服务器，同时也接收服务器返回的响应并转发给客户端**。

### 代理分类基准

代理有多种使用方法，按两种基准分类。一种是是否使用缓存，另一种是是否会修改报文。

缓存代理：代理转发响应时，缓存代理会预先**将资源的副本（缓存）保存在代理服务器上**。当代理再次接收到对**相同资源的请求**时，就可以**不从源服务器那里获取资源，而是将之前缓存的资源作为响应返回**。

透明代理：转发请求或者响应时，**不对报文做任何加工的代理类型被称为透明代理**。反之，**对报文内容进行加工的代理被称为非透明代理**。

## 网关

网关是**转发其他服务器通信数据的服务器**，接收从客户端发送来的请求时，他**就像自己拥有资源的服务器一样对请求进行处理**。有时候客户端可能不会察觉，自己的通信目标是一个网关。

网关的工作机制和代理十分相似。但是网关**能使通信线路上的服务器提供非`HTTP`协议服务**。**利用网关能够提高通信的安全性，因为可以在客户端与网关之间的通信线路上加密以确保连接安全。**

![image-20220105212906162](https://github.com/NoAlligator/pico/blob/main/img/image-20220105212906162.png?raw=true)

## 隧道

隧道是在**相隔甚远的客户端和服务器两者之间进行中转**，并保持双方通信连接的应用程序。

隧道可**按要求建立起一条与其他服务器的通信线路，届时使用`SSL`等加密手段进行通信**。隧道的目的时确保**客户端能与服务器进行安全的通信**。协议本身不会去解析`HTTP`请求，即**请求保持原样中转给之后的服务器**。隧道会在通信双方断开连接时结束。

![image-20220105222839510](https://github.com/NoAlligator/pico/blob/main/img/image-20220105222839510.png?raw=true)

## 源服务器

持有**资源实体**的服务器被称为**源服务器**。从源服务器返回的响应经过代理服务器后再传给客户端。

# 4.有了`IP`地址为什么还需要`MAC`地址？

[参考答案](https://www.zhihu.com/question/21546408/answer/2303205686)

[参考](https://juejin.cn/post/7059313549255901191)

如果一台计算机被部署在一个局域网中，它会被分配到一个私有IP地址（例如192.0.0.1），而这个私有IP地址是外部网络无法直接访问的，所以请求会被先发送到路由器当中，然后由路由器进行转发，这个时候请求报文的源IP地址就会被记录为路由器所对应的公网IP地址（通过NAT路由器获得外网IP）；

之后当前报文的响应报文也会发送到该IP地址所对应的设备，也就是该路由器，但是路由器往往会通过交换机连接更多的设备，为了将报文精准的发送到对应的设备，就需要一个设备独立标识符，也就是设备MAC地址，因为发送请求的时候会携带上源MAC地址，所以响应也会带上这个源MAC地址以便能够顺利到达对应的设备。最后，路由器会根据ARP协议中的ARP缓存表进行MAC地址和私有IP地址的映射，这样就能够将数据发送到所需的设备中了。

# 5.说一说`CDN`?

## `CDN`概述

`CDN（内容分发网络）`全称是 `Content Delivery Network`，建立并覆盖在承载网之上、由分布在不同区域的边缘节点服务器群组成的分布式网络，替代传统以 `WEB Server` 为中心的数据传输模式。作用是**将源内容发布到边缘节点**，配合精准的**调度系统**；将用户的请求分配至最适合他的节点，使用户可以以最快的速度取得他所需的内容，有效解决`Internet`网络拥塞状况，提高用户访问的响应速度。

## `CDN`基本工作过程

用户通过浏览器等方式访问网站的过程如图所示：

![image](https://github.com/NoAlligator/pico/blob/main/img/1460000010631407?raw=true)

1. 用户在自己的浏览器中输入要访问的网站域名。
2. 浏览器向 **本地`DNS`服务器** 请求对该域名的解析。
3. 本地`DNS`服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求。
4. 本地`DNS`服务器中如果没有关于这个域名的解析结果的缓存，则以递归（迭代）方式向整个`DNS`系统请求解析，获得应答后将结果反馈给浏览器。
5. 浏览器得到域名解析结果，就是该域名相应的服务设备的 **`IP`地址** 。
6. 浏览器向服务器请求内容。
7. 服务器将用户请求内容传送给浏览器。

在网站和用户之间加入 `CDN`以后，用户不会有任何与原来不同的感觉。最简单的 `CDN` 网络有**一个 `DNS` 服务器和几台缓存服务器**就可以运行了。一个典型的 `CDN` 用户访问**调度流程**如图所示：

![image](https://github.com/NoAlligator/pico/blob/main/img/1460000010631408?raw=true)

1. 当用户点击网站页面上的内容`URL`，经过本地`DNS`系统解析，`DNS` 系统会最终将域名的解析权交给 [`CNAME`](https://link.segmentfault.com/?enc=F5%2BI7pKgtchHv6M4Qm4mCw%3D%3D.vIopsuN6th4m1%2BN8Bt%2B85Mzyk%2BOnKW%2B9fnZagUcZP59gFTIBSDyyOd3KUxzeLq%2FT) 指向的 **`CDN` 专用 `DNS` 服务器**。
2. `CDN` 的 `DNS` 服务器将 `CDN` 的全局负载均衡设备 `IP` 地址返回用户。
3. 用户向 `CDN` 的全局负载均衡设备发起内容 `URL` 访问请求。
4. `CDN` 全局负载均衡设备根据用户 `IP`地址，以及用户请求的内容`URL`，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。
5. 基于以下这些条件的综合分析之后，**区域负载均衡设备会向全局负载均衡设备**返回一台缓存服务器的`IP`地址：
   - 根据用户 `IP` 地址，判断哪一台服务器距用户**最近**；
   - 根据用户所请求的 `URL` 中携带的内容名称，判断哪一台服务器上有用户所需内容；
   - 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。
6. 全局负载均衡设备把**服务器的 `IP` 地址**返回给用户。
7. 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

**`DNS` 服务器根据用户 `IP` 地址，将域名解析成相应节点的缓存服务器`IP`地址，实现用户就近访问。**使用 `CDN` 服务的网站，只需将其域名解析权交给 `CDN` 的全局负载均衡（`GSLB`）设备，将需要分发的内容注入 `CDN`，就可以实现内容加速了。

使用`CDN`后的**`http`请求处理流程**如下图，其中左边为**`DNS`解析过程**，右边为**内容访问过程**：

![image](https://segmentfault.com/img/remote/1460000010631409)

## 其余内容

[参考链接](https://segmentfault.com/a/1190000010631404#)

# 6.功能概述

## 物理层 以太网

传输比特流，数据传输的物理规范；

## 数据链路层 以太网

封装成帧（例如以太网MAC帧，在数据头部加上源MAC地址和目标地址，数据尾部加上帧检验序列）；透明传输（防止信息和控制信息混淆，字符编码）；差错控制（海明码）；流量控制和可靠传输（选择重传协议）；

## 网络层（网际层）IP

路由选择和转发（路由算法：OSPF、RIP、BGP）；异构网络互联；拥塞控制；

## 传输层 TCP UDP

**传输层**就是将进程和收到的数据通过端口号联系到一起，使数据能够为应用服务，所以说传输层是**主机**才有的层次。

## 应用层 HTTP FTP POP3 SMTP

应用层通过具体的协议为进程间网络通信提供服务，是直接产生完整报文的层次。

# 7.私有IP地址和特殊IP地址

> IP地址是一个**全球唯一的**表示**某一个主机或者路由器接口**在网络所处的位置的编码。

## 私有

地址按用途分为私有地址和公有地址两种。**所谓私有地址就是在A、B、C三类IP地址中保留下来为企业内部网络分配地址时所使用的IP地址。**私有地址主要用于在局域网中进行分配，在 Internet上是无效的。这样可以很好地隔离局域网和 Internet。私有地址在公网上是不能被识别的，必须通过**网络地址转换（NAT）**将内部IP地址转换成公网上可用的IP地址，从而实现内部IP地址与外部公网的通信。公有地址是在广域网内使用的地址，但在[局域网](https://baike.baidu.com/item/局域网/98626)中同样也可以使用，除了私有地址以外的地址都是公有地址。

### NAT

连接**内网和外网**，就是找个代理的用它的IP地址与外面收发数据。NAT需要构建NAT转换表，既要存广域网（`WAN`，外网）也要存局域网（`LAN`，内网）的IP地址和端口号。在专用网连接到因特网的路由器上安装NAT软件，安装了NAT软件的路由器叫做NAT路由器，他至少有一个有效的外部全网IP地址。

## 特殊

在IP地址中有一些并不是来**标注主机**的，这些地址具有特殊的意义。这些地址包括网络地址、**直接广播地址**、受限广播地址、**本网络地址**、**环回地址**等。

# 8.套接字

> 套接字 = 主机`IP` + 端口号

所谓套接字(Socket)，就是对网络中**不同主机上的应用进程之间进行双向通信的端点的抽象**。一个套接字就是网络上进程通信的一端，提供了应用层进程利用网络协议交换数据的机制。从所处的地位来讲，套接字上联应用进程，下联网络协议栈，是应用程序通过网络协议进行通信的接口，是应用程序与网络协议栈进行交互的接口。

# 9.UDP和TCP

## UDP

> 应用层给UDP多长的报文，UDP就会照样发送，即一次发送一个完整报文，所以需要应用层传输过来的数据**不要太大**，否则网络层分片任务就很重，但是也**不能太小**，不然效率较低，`UDP`适合一些实时应用，因为**实时应用延迟要求高，需要立即响应**。

1. 无连接，减少开销和建立连接的时延，传输效率高；
2. 面向报文协议，无重传机制，不保证可靠交付；
3. 无拥塞控制；
4. 首部开销小；
5. UDP数据报有**校验和**字段，可以确保数据的可靠性；

## TCP

1. 面向连接的协议，需要建立连接后进行可靠通信，有建立连接的开销，传输效率相对低；
2. 提供可靠传输；
3. 提供全双工通信（具体的例子就是`WebSocket`）；

# 10.TCP如何确保可靠传输，流量控制，拥塞避免

## 可靠传输

### 校验

增加伪首部，类似于UDP校验，确保数据的**可靠性**；

### 序号

就是`TCP`根据下方数据链路层的`MTU`（最大传输单元）来随即将**数据切割**成好几段并且进行**编号**。通过序号辨别报文段在完整报文中的的位置，确保数据的**有序性和正确性**；

### 累计确认

采用累计确认的方式确认已经接受到的数据，确保数据传输的**有序性**；

### 重传

重传机制使得客户端在被通知或者预测到丢包发生之后能够重新发送丢失序号对应的报文段，例如：**自适应超时重传算法**、快速重传；

## 流量控制和拥塞控制区别

> 流量控制由接收方根据自身情况决定，防止发送方发送太快导致大量丢包；
>
> 拥塞控制由发送方的网络等情况决定，防止TCP请求发送太快造成对其他资源的拥塞；
>
> 流量控制对应一个接收窗口`rwnd`，拥塞控制对应一个拥塞窗口`cwnd`，发送端的具体发送窗口由两者的最小值决定；

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

## 流量控制

### 滑动窗口

[滑动窗口协议](https://www.zhihu.com/search?q=滑动窗口协议&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A68558623})是**传输层进行流控**的一种措施，**接收方通过通告发送方自己的窗口大小**，从而控制发送方的**发送速度**，从而达到防止发送方发送速度过快自己来不及接收而导致丢包。

## 拥塞控制

[参考](https://www.cnblogs.com/xiaolincoding/p/12732052.html)

[参考](https://juejin.cn/post/6900439208641921038#heading-11)

### 慢开始 + 拥塞避免

慢启动从拥塞窗口等于1开始指数增长，这个称作慢启动；

当窗口增大到慢启动门限之后变成相信增长，这个称作拥塞避免；

如果发送拥塞，就将门限减半，拥塞窗口迅速降为1，重新进入上述阶段；

### 快重传 + 快恢复 + 拥塞避免

快重传规定，发送方只要连续收到**3个重复确认**，立即重传对方发来的M2（重复确认报文的后一个报文）；

快恢复规定，当发送方连续收到**三个重复确认**，拥塞门限减半；由于发送方可能认为网络现在没有拥塞，因此与慢启动不同，把拥塞窗口值设置为**门限减半**之后的值，然后执行拥塞避免算法，门限线性增大；

# 11.DNS域名解析系统

> `DNS`指的是域名解析系统，它是将具体的域名解析为真实的`IP`地址的系统。

## 域名服务器

`DNS`服务器有很多台，根据层次结构分为**三层**：**根域名服务器，顶级域名服务器，权限域名服务器**。

**根域名服务器**并不是一个域名只有一台，而是**一个域名对应多台域名服务器**，全世界一共有`13`个这样的域名，分别是`a.rootservers.net`，`b.rootservers.net`，`c.rootservers.net`，`----`，`m.rootservers.net`。根域名服务器**掌握了所有顶级域名服务器的`IP`地址**。

在**权限域名服务器**中，虽然看似`abc.com`比`y.abc.com`少了一位，但是他们的**地位仍是对等**的，**对应的两台权限域名服务器**。

**本地域名服务器**不算层次结构，特点是**离主机比较近**，当主机和另一台**比较近的主机通信**时，就不用走那些**更高级**的服务器。

## 域名解析

![在这里插入图片描述](https://github.com/NoAlligator/pico/blob/main/img/20200702223220720.png?raw=true)

### 迭代查询

主机先是向**本地域名服务器**发送请求，如果查不到的话，本地域名服务器向根域名服务器发送请求（找别人），如果还是查不到的话，根域名域名服务器向顶级域名服务器发送请求（找别人），如果还是查不到的话，顶级域名服务器向权限域名服务器发送请求（找别人）。可以看到每一次向下一个查询的服务器都变了，不是主机一个个去问，而是服务器自己一个个问下去。

### 递归查询

主机先是向**本地域名服务器**发送请求，如果查不到的话，本地域名服务器就让主机去向根域名服务器发送请求（主机去找，本地域名给目标根域名服务器的IP地址），如果还是查不到的话，根域名域名服务器让主机去向对应的顶级域名服务器发送请求（主机去找，根域名给目标顶级域名服务器的`IP`地址），如果还是查不到的话，顶级域名服务器让主机去向权限域名服务器发送请求（主机去找，顶级域名给目标权限域名服务器的`IP`地址）。可以看到这里是主机一个个挨个问的地址。

### 高速缓存

为了减少**多次查询同一个域名的资源浪费**，本地域名服务器会存储最近使用的`IP`地址解析，下次再访问同一个域名就不需要这么多查询步骤了。同时这个高速缓存主机本身也有存储，**本地域名服务器还可以对顶级域名服务器，权限域名服务器的地址进行缓存**，下一次即使是不知道的`IP`地址，查询也可以更快。高速缓存为了保持正确性，需要**定时更新**。

# 12.输入URL发生了什么？

#### 1.DNS解析

浏览器DNS缓存、本地DNS缓存、本地域名解析服务器、根域名解析服务器、顶级域名解析服务器、权限域名解析服务器（迭代查询、递归查询）

#### 2.建立TCP连接（三次握手）

#### 3.TLS协商

#### 4.接收数据（HTML）

#### 5.解析HTML，构建DOM树，与此同时预加载扫描仪会并行下载其他资源

#### 6.解析CSS并构建CSSOM树

#### 7.如果此时脚本还没有加载完成，会立即进入脚本加载前的第一次渲染（这是为了用户能够更快的看到首屏内容）

#### 8.从DOM树的根节点开始将DOM和CSSOM树组合成一个渲染树

#### 9.在渲染树上运行布局以确定最终页面上各个元素大小以及位置

#### 10.如果存在分层，会依次进行合成、生成绘制列表、光栅化

#### 11.显示首屏内容

#### 12.脚本加载完成后执行整体脚本代码，也就是一个宏任务，并在下一个宏任务之前清空微任务队列

#### 13.触发onDomContentLoaded事件，但是外部资源未完全下载

#### 14.外部资源完全下载完成，触发onload事件

#### 15.对其他资源进行预取，DNS预解析

> DNS解析、TCP连接、TLS协商、请求HTML并构建DOM树，同时预加载扫描器开启资源同步下载，当CSS加载完成后会立即被解析成CSSOM、读取到尾部外链脚本，如果脚本还没有加载完成的话，抢先进行首屏渲染、合成渲染树、进行布局、合成、生成绘制列表、光栅化、最后完成首席渲染、在脚本完成后立即执行整体脚本代码（宏任务）并清空这一轮宏任务积累的微任务队列，触发onDomContentLoaded事件、外部资源悉数加载完成，触发onload事件、进行资源预取和DNS预解析。

